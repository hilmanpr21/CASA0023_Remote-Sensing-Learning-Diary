<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.115">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>RS_Learning_diary - 3&nbsp; week03 - Remote Sensing Data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./week04.html" rel="next">
<link href="./week02.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">week03 - Remote Sensing Data</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">RS_Learning_diary</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome to my learning diaries</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week01.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">week 01 - Remote Sensing Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week02.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">week02 - Sensor Satellite Presentation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week03.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">week03 - Remote Sensing Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week04.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">week04 - Policy</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week05.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">week_05 - Google Earth Engine</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week06.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">week_06 - Classification</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week07.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">week_07 - Classification Continue</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week08.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">week_08 - Temperature and Policy</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary"><span class="toc-section-number">3.1</span>  Summary</a>
  <ul class="collapse">
  <li><a href="#correction" id="toc-correction" class="nav-link" data-scroll-target="#correction"><span class="toc-section-number">3.1.1</span>  Correction</a></li>
  <li><a href="#joining-datasetsenhancement" id="toc-joining-datasetsenhancement" class="nav-link" data-scroll-target="#joining-datasetsenhancement"><span class="toc-section-number">3.1.2</span>  Joining Datasets/Enhancement</a></li>
  <li><a href="#image-enhancement" id="toc-image-enhancement" class="nav-link" data-scroll-target="#image-enhancement"><span class="toc-section-number">3.1.3</span>  Image Enhancement</a></li>
  </ul></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application"><span class="toc-section-number">3.2</span>  Application</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection"><span class="toc-section-number">3.3</span>  Reflection</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">week03 - Remote Sensing Data</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="summary" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">3.1</span> Summary</h2>
<p>In this week we learn about history of Landsat data and pre-processing of imagery satellite data.</p>
<p>We have to thank Virginia Wood for the landsat data we have nowadays because previously NASA wanted to use analogue system (RBV camera - TV camera with Green, Red and NIR spectrum) for their sensor. This is the spectral that catch by the Landsat RBV, and then cutted into only 4 bands, green, red, red-near IR, and near-IR. Then, Virginia Norwood suggested to use <strong>Multispectal Camera (MSS)</strong> which allows us to have 7 bands image. This became standar for the following landsat. Since then she is known as “the Mother of Landsat”</p>
<p>Preprocessing step is a step we do to make our imagery data ready to be processed (classified) or analysed. It can be seen on the mind map that preprocessing steps we can do 3 thing, which are: 1. Correction 2. Data Joining 3. Enhancement Not every imagery data required all these 3 steps, it depends on the data we get and what we are going to do. Check this mind map to understand the outline of pre-processing steps.</p>
<section id="correction" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="correction"><span class="header-section-number">3.1.1</span> Correction</h3>
<ul>
<li>Pre-processings are required (occasionally) because imagery data can contain flaws or errors from the sensor, atmosphere, terrain and more</li>
<li><strong>Scan Line Correction (SLC)</strong> is pair of mirror to compansate the forward movement of satellite so the resulting scan are shown paralel
<ul>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/SLC.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">GEE Interface</figcaption><p></p>
</figure>
</div></li>
<li><p>Failed scan line landsat is on Landsat 7, because it moves in a zig zag, and the corrector made the image normal</p></li>
<li><p>Imagery was still distributed but it is hard to use with methods developed to estimates the gaps, termed gap filling.</p></li>
</ul></li>
</ul>
<section id="geometric-correction" class="level4" data-number="3.1.1.1">
<h4 data-number="3.1.1.1" class="anchored" data-anchor-id="geometric-correction"><span class="header-section-number">3.1.1.1</span> 1. Geometric Correction</h4>
<ul>
<li><p>Means geometry on how the image located on earth.</p></li>
<li><p>Satelite image has CRS (Coordinate Reference System)</p></li>
<li><p>Image distortions can be introduce due to:</p>
<ul>
<li>View angle (off-nadir)* - <a href="https://space.stackexchange.com/questions/19727/in-spacecraft-talk-is-nadir-just-a-fancy-word-for-down">Nadir means directly down</a></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/view angle.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">View Angle</figcaption><p></p>
</figure>
</div>
<pre><code>  - if the satelite off nadir, it will cause shadowing  and we have to correct it</code></pre>
<ul>
<li>Topography (e.g.&nbsp;hills not flat ground)</li>
<li>Wind (if from a plane)</li>
<li>Rotation of the earth (from satellite)
<ul>
<li>because of the earth rotation, the image produced will be off grid, so it has to be aligned</li>
<li><img src="week_03_files/satellite rotation.png" title="fig:" class="img-fluid" style="width:100.0%" alt="satellite rotation"></li>
</ul></li>
</ul></li>
</ul>
<section id="geometric-correction-solution" class="level5" data-number="3.1.1.1.1">
<h5 data-number="3.1.1.1.1" class="anchored" data-anchor-id="geometric-correction-solution"><span class="header-section-number">3.1.1.1.1</span> Geometric Correction Solution</h5>
<ul>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/Geometric correction solution.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Geometric correction solution</figcaption><p></p>
</figure>
</div></li>
<li><p><strong>Steps</strong>:</p>
<ol type="1">
<li>identify Ground Control Points (GCP) to match known points in the image and a reference dataset
<ul>
<li>Reference Dataset can be:
<ul>
<li>Local Map</li>
<li>Another image</li>
<li>GPS data from handheld device</li>
</ul></li>
<li>GCP typically using object that does not move, such as:
<ul>
<li>Parking lot</li>
<li>Building</li>
<li>(typically non-vegetation)</li>
</ul></li>
</ul></li>
<li>Take the coordinates and the model them to give geometric transformation coefficients</li>
<li>Transform the GCP coordinates to the right one using linear regressrion</li>
<li>plot these and try to minimise the RMSE</li>
</ol></li>
<li><p><strong>Modelling</strong></p>
<ul>
<li><strong>Forward mapping</strong>
<ul>
<li><p>predicting corrected image with uncorrected image</p></li>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/forward mapping formula.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Forward Mapping formula</figcaption><p></p>
</figure>
</div></li>
<li><p>&nbsp;<em>x</em>&nbsp;and&nbsp;<em>y</em>&nbsp;are positions in the corrected map</p></li>
<li><p>But the issue is that we are modelling the rectified&nbsp;<em>x</em>&nbsp;and&nbsp;<em>y</em>&nbsp;which could fall anywhere on the gold standard map (e.g.&nbsp;not on a grid square or at a floating point)</p></li>
<li><p>forward mapping isn’t the most common one to use</p></li>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/forward mapping.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Forward Mapping</figcaption><p></p>
</figure>
</div></li>
</ul></li>
<li><strong>Backward Mapping</strong>
<ul>
<li><p>Predicting the uncorrected image with the corrected image</p></li>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/backward mapping formula.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Backward Mapping</figcaption><p></p>
</figure>
</div></li>
<li><p>Every value in the output (corrected image) pixel will have value in the original input (uncorrected) image.</p></li>
<li><p>the images are distorted so might not completely overlap. The goal is to match distorted image with gold standard image, so we want the pixel to line up</p></li>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/backward mapping.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Backward Mapping</figcaption><p></p>
</figure>
</div></li>
</ul></li>
</ul></li>
<li><p><strong>Resampling</strong></p>
<ul>
<li>resampling is transforming from grid to another grid</li>
<li>we need to do re-sampling because the image data we get might slightly shifted. ANd is can be useful if the image has different grid size (or different band that has different resolution, like in the 1st week practical)</li>
<li><img src="week_03_files/resampling.png" title="fig:" class="img-fluid" style="width:80.0%" alt="resampling"></li>
</ul></li>
</ul>
</section>
</section>
<section id="atmospheric-correction" class="level4" data-number="3.1.1.2">
<h4 data-number="3.1.1.2" class="anchored" data-anchor-id="atmospheric-correction"><span class="header-section-number">3.1.1.2</span> 2. Atmospheric Correction</h4>
<ul>
<li>Atmospheric correction is the influence of atmospher on our data:
<ul>
<li>Atmospheric scattering</li>
<li>topography Attenuation (reduction)</li>
</ul></li>
<li>The goal is to remove the influence of atmosphere</li>
<li>Situation where necessary or unnecessary to do atmospheric correction:
<ul>
<li><strong>Unnecessary</strong>
<ul>
<li>if just look into one single images, because we dont have to see data across time</li>
</ul></li>
<li><strong>Necessary</strong>
<ul>
<li>typically if we have time constrain. To compare data in multiple time stamp</li>
</ul></li>
</ul></li>
<li><strong>Scattering</strong> create haze that reduce the contrast pf the image</li>
<li>bright reflective material, eg, concrete, asphalt. karena terlalu terang jadi bocor ke sekitarnya</li>
</ul>
<section id="atmospheric-correction-solution" class="level5" data-number="3.1.1.2.1">
<h5 data-number="3.1.1.2.1" class="anchored" data-anchor-id="atmospheric-correction-solution"><span class="header-section-number">3.1.1.2.1</span> Atmospheric Correction Solution</h5>
<ul>
<li><strong>Relative</strong>
<ul>
<li>Adjust some data relative to something else as reference</li>
<li>Type
<ul>
<li><strong>Dark object subtraction (DOS)</strong>
<ul>
<li>Done by searching dark value (usually water) of each band and substract that value from each pixel</li>
</ul></li>
<li><strong>Psuedo-invariant Features (PIFs)</strong>
<ul>
<li>this used when we have may images. We pick 1 image as based image. Determine feature that don’t change. Make regression model with Y is the based image. Adjust the ijmage based on regression model</li>
<li><img src="week_03_files/Pseudo invariant feature.png" class="img-fluid" style="width:70.0%" alt="Pseudo invariant feature"> Pseudo invariant feature</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Absolute</strong>
<ul>
<li>Change digital brightness values into scaled surface reflectance. We can&nbsp;<strong>then compare these scaled surface reflectance values across the planet</strong></li>
<li>Basically made atmospheric model called <strong>atmospheric radiative transfer models</strong></li>
</ul></li>
</ul>
</section>
</section>
<section id="topography-correction-orthorectification-correction" class="level4" data-number="3.1.1.3">
<h4 data-number="3.1.1.3" class="anchored" data-anchor-id="topography-correction-orthorectification-correction"><span class="header-section-number">3.1.1.3</span> 3. Topography Correction/ Orthorectification Correction</h4>
<ul>
<li><p>it means when we are not looking straight down (nadir), so the image distorted.</p></li>
<li><p><strong>orthorectification</strong> means removing distortion by making the pixel viewed at nadir</p></li>
<li><p>for orthorectification we need sun zenith and azimut angle, and orientation of the slope from DEM.</p></li>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/zenith azimut.png" class="img-fluid figure-img" style="width:70.0%"></p>
<p></p><figcaption class="figure-caption">Zenith Azimut ilustration</figcaption><p></p>
</figure>
</div>
<ul>
<li>Zenith meas directly up while nadir means directly down</li>
<li>Azimut is position of sun to north, south, east, west</li>
</ul></li>
<li><p><strong>Atmospheric typically happen before topographic correction</strong></p></li>
</ul>
</section>
<section id="radiometric-calibration" class="level4" data-number="3.1.1.4">
<h4 data-number="3.1.1.4" class="anchored" data-anchor-id="radiometric-calibration"><span class="header-section-number">3.1.1.4</span> 4. Radiometric Calibration</h4>
<ul>
<li>Sensor capture image as Digital Number with no units. Spectral Radiance is the amount of light within a &nbsp;band from a sensor in the field of view</li>
<li><strong>Radiometric Calibration</strong>: Calibrate the data (digital Number) into radiance and convert to specific unit
<ul>
<li><strong>Radiance</strong> refers to any <strong>radiation leaving the Earth</strong> (i.e.&nbsp;upwelling, toward the sensor</li>
</ul></li>
<li>basically, before sending sensor to the space, calibaration was done to check whether sensors performing correctly or not. We then use the calibration measurements to adjust the data captured by the sensor</li>
<li><img src="week_03_files/Radiometric Calibration.png" title="fig:" class="img-fluid" style="width:70.0%" alt="Radiometric Calibration"></li>
</ul>
</section>
</section>
<section id="joining-datasetsenhancement" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="joining-datasetsenhancement"><span class="header-section-number">3.1.2</span> Joining Datasets/Enhancement</h3>
<ul>
<li>the ideas is joining or merging or mosaicking or feathering images into one seamless image</li>
<li>This process was done by taking few pixel from each image at the same location and overlaping those pixels. Then, blending these to image on the ovelaped pixels</li>
<li>Those image are ovelapping by 20-30%</li>
<li><img src="week_03_files/Data Join.png" class="img-fluid" style="width:75.0%" alt="Data Join"> source <a href="https://www.l3harrisgeospatial.com/docs/mosaicseamless.html">Seamless Mosaic (l3harrisgeospatial.com)</a></li>
<li><img src="week_03_files/Data Join result.png" title="fig:" class="img-fluid" style="width:100.0%" alt="Data Join result"></li>
</ul>
<p>source <a href="https://gis.stackexchange.com/questions/127310/how-to-create-a-mosaic-in-qgis-with-cutline-and-feathering-for-landsat-8-imagery">gdal - How to create a mosaic in QGIS with cutline and feathering for Landsat-8 imagery - Geographic Information Systems Stack Exchange</a> - However the challenge is the image we get might coming from different day and lighting condition or even different satellite. It can cause different band value thus those image have to undergo standarisation and normalisation - <strong>Standarisation</strong> by dividing the SR value by a maximum value per band - <strong>normalisation</strong> by divide the standarised value by the sum of values across all bands</p>
</section>
<section id="image-enhancement" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="image-enhancement"><span class="header-section-number">3.1.3</span> Image Enhancement</h3>
<ul>
<li>it doesn’t alter the value of the data, merely changing how it explains and visual appearance</li>
</ul>
<section id="contrast-enhancement" class="level4" data-number="3.1.3.1">
<h4 data-number="3.1.3.1" class="anchored" data-anchor-id="contrast-enhancement"><span class="header-section-number">3.1.3.1</span> Contrast Enhancement</h4>
<ul>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/contrast enhancement.png" class="img-fluid figure-img" style="width:75.0%"></p>
<p></p><figcaption class="figure-caption">contrats enhancemenct</figcaption><p></p>
</figure>
</div></li>
<li><p>done by:</p>
<ul>
<li>stretching min max value</li>
<li>percentage Linear and Standar Deviation</li>
<li>Piecewise Linear Contrast Stretch</li>
</ul></li>
<li><p>it doesn’t alter the value of the data, merely changing how it explains and visual appearance</p></li>
</ul>
</section>
<section id="ratio-enhancement" class="level4" data-number="3.1.3.2">
<h4 data-number="3.1.3.2" class="anchored" data-anchor-id="ratio-enhancement"><span class="header-section-number">3.1.3.2</span> Ratio enhancement</h4>
<ul>
<li>band ratioing means dividing bands by each other</li>
<li>eg: Normalize Burn Ratio
<ul>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/ratio enhancement.png" class="img-fluid figure-img" style="width:75.0%"></p>
<p></p><figcaption class="figure-caption">ratio enhancement</figcaption><p></p>
</figure>
</div></li>
<li><p>source: <a href="https://www.usgs.gov/landsat-missions/landsat-normalized-burn-ratio">Landsat Normalized Burn Ratio | U.S. Geological Survey (usgs.gov)</a></p></li>
</ul></li>
</ul>
</section>
<section id="filtering" class="level4" data-number="3.1.3.3">
<h4 data-number="3.1.3.3" class="anchored" data-anchor-id="filtering"><span class="header-section-number">3.1.3.3</span> Filtering</h4>
<ul>
<li>means taking an image an having a moving window to see aggregation of the image. Calculate surround pixel and put the average value as the middle pixel’ value</li>
<li>Low Pass or low frequency is average of the surrounding pixels</li>
<li>High pass or high frequency is enhance local vatiations</li>
<li><img src="week_03_files/filtering.png" title="fig:" class="img-fluid" style="width:75.0%" alt="Filtering"></li>
</ul>
</section>
<section id="principal-component-analysis" class="level4" data-number="3.1.3.4">
<h4 data-number="3.1.3.4" class="anchored" data-anchor-id="principal-component-analysis"><span class="header-section-number">3.1.3.4</span> Principal Component Analysis</h4>
<ul>
<li>Using PCA we can make our data smaller and maximise variation between our data</li>
<li>PCA will transforming multi-spectral data into uncorrelated and smaller data set</li>
<li>Reduce dimensionality</li>
<li>Example:
<ul>
<li><p>multi-temporal PCA bands from both time points are combined into one image, then PCA</p></li>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/PCA.png" class="img-fluid figure-img" style="width:75.0%"></p>
<p></p><figcaption class="figure-caption">PCA</figcaption><p></p>
</figure>
</div></li>
<li><p>so initially there are 2 or 3 images from different time stamps. It was stacked together and did PCA. From the PCA,they classify land use changes. Then maximise the variation.</p></li>
</ul></li>
</ul>
</section>
<section id="texture-enhancement" class="level4" data-number="3.1.3.5">
<h4 data-number="3.1.3.5" class="anchored" data-anchor-id="texture-enhancement"><span class="header-section-number">3.1.3.5</span> Texture Enhancement</h4>
<ul>
<li>Textture is spatial variation of gray value</li>
<li>usually used for medical detection</li>
<li>Texture analysis looks at the tonal feature of the image by looking at the surrounding values. So there’s a moving window with 3x3 grid and it will calculate the value of a pixel with variance and probability of surrounding (within the window) value</li>
<li>Texture variance result
<ul>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/texture enhancement.png" class="img-fluid figure-img" style="width:75.0%"></p>
<p></p><figcaption class="figure-caption">Texture Enhancement</figcaption><p></p>
</figure>
</div></li>
<li><p>sisi yang terang adalah pinggir2 gedung karena tepi texture has high variance value</p></li>
</ul></li>
<li>Texture is beneficial to give additional information to our model as it oppose to just relying on spectral reflectance. Thus we can improve our classification model.</li>
</ul>
</section>
<section id="data-fusion-enhancement" class="level4" data-number="3.1.3.6">
<h4 data-number="3.1.3.6" class="anchored" data-anchor-id="data-fusion-enhancement"><span class="header-section-number">3.1.3.6</span> Data Fusion enhancement</h4>
<ul>
<li>stack of multiband data fused with PCA or texture or other enhancement.</li>
<li>Image fusion can alse be from different sensor. eg. Sentinel fused with Landsat</li>
<li>usually it take the median value of each pixel of each band.</li>
</ul>
</section>
</section>
</section>
<section id="application" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="application"><span class="header-section-number">3.2</span> Application</h2>
<p>Learning about image enhancement in pre-processing step are really beneficial especially when we are dealing with huge datasets, such as hyperspectral and multi-temporal imagery <span class="citation" data-cites="rodarmelPrincipalComponentAnalysis2002">(<a href="references.html#ref-rodarmelPrincipalComponentAnalysis2002" role="doc-biblioref">Rodarmel and Shan, 2002</a>)</span>. Principal Component Analysis enhancement is a tools to reducing dimensionality if we are detecting land-use change from time to time using stacked multi-date data like what Deng <span class="citation" data-cites="dengPCABasedLand2008">(<a href="references.html#ref-dengPCABasedLand2008" role="doc-biblioref">2008</a>)</span> in their paper. In detecting land-use change in Hangzhou City, China, they also use data from various sensors which are aerial photograph, SPOT-5 and Landsat-7. !<img src="week_03_files/PCA 1.png" class="img-fluid" style="width:100.0%"></p>
<p>The image above shows one example of land use change from cropland to urban land. These image shows:</p>
<p><em>a</em> ETM in 2000</p>
<p><em>b</em> aerial photograph in 2000</p>
<p><em>c</em> SPOT-5 in 2003</p>
<p><em>d</em> Ikonos in 2003</p>
<p><em>e-h</em> are the principal component.</p>
<p>source: Deng <span class="citation" data-cites="dengPCABasedLand2008">(<a href="references.html#ref-dengPCABasedLand2008" role="doc-biblioref">2008</a>)</span> Using PCA wil make it easier to see detect the change because it will produce a new image (Principal component) that intensify the change <span class="citation" data-cites="ingebritsenPrincipalComponentsAnalysis1985">(<a href="references.html#ref-ingebritsenPrincipalComponentsAnalysis1985" role="doc-biblioref">Ingebritsen and Lyon, 1985</a>)</span>. In Deng’s paper, PCA was used to combining image band that taken from two different times into one new image. Changed area will have high correlation between two image, meanwhile unchanged are will have low correlation. Afterwards Deng classified and labelled the correlation value to detect changing area.</p>
<p>In this analysis the usage of PCA on multitemporal and multisensor data shows high accuracy value which is 89.54%. Other application of PCA in hyperspectral done by Rodarmel <span class="citation" data-cites="rodarmelPrincipalComponentAnalysis2002">(<a href="references.html#ref-rodarmelPrincipalComponentAnalysis2002" role="doc-biblioref">2002</a>)</span>, also shows satisfying result with 70% correct classification rate. Rodarmel and Shan, use hyperspectral data to detect component of land cover, such as, vegetation, mineral and soil type. They stacked band 1-5, 1-10 and 1-25 from HYDICE image and use PCA to generate 4 different PC images. Afterwards they classified the result of each PCA image and compared with original image PCA. The result shows PCA from band 1-5 is contain most information, while bands beyond 10 only contain noise.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="week_03_files/PCA 2.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Flood in Semarang</figcaption><p></p>
</figure>
</div>
<p>source: Principal Component Analysis for Hyperspectral Image Classification</p>
<p>Although, PCA helps reducing image dimensionality, the output does not give much information. It has to be processed using image classification, as shown in the 2 paper I discussed above <span class="citation" data-cites="licciardiLinearNonlinearPCA2012">(<a href="references.html#ref-licciardiLinearNonlinearPCA2012" role="doc-biblioref">Licciardi <em>et al.</em>, 2012</a>)</span>. We can say that output of PCA is input for other analysis. Thus, to do a robust analysis, we also need to learn about methods other than image enhancement.</p>
</section>
<section id="reflection" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="reflection"><span class="header-section-number">3.3</span> Reflection</h2>
<p>This week content about image correction, data joining and enhancement are really interesting because it is beneficial in practical and academical context. Imagery data that we get from sensor is not always perfect, it might have some error that come from the atmospher or the sensor itself. Especially in some region with high degree of moist, acquiring clear image is a challenge due to the existance of cloud <span class="citation" data-cites="dengPCABasedLand2008">(<a href="references.html#ref-dengPCABasedLand2008" role="doc-biblioref">Deng <em>et al.</em>, 2008</a>)</span>. This can be tackled by atmospheric correction or if we use multitemporal data we can do PCA. Not only from external factors, but image error can also happend because the radiometric calibration of the sensor. Thus, to conduct an accurate and robust analysis we have to reduce the error by doing corrections.</p>
<p>Image enhancement helps to handle huge data set from multi-temporal, multispectral, and multi-sensor images. This is beneficial to see the change of land use. For developing countries, where development happen organically, a lot of residential built without permission so the government does not have the data about land usage in the city. By using remote sensing to detect the land-use changing will help government to be aware of the informal residential and observe where informal development tend to happen over time.</p>
<p>However, we cannot just stop at learning about image enhancement because it only give us input for further analysis. We should also learn about image classification to detect land use and land coverage. For classification methods you can go to chapter 6 and 7.</p>


<div id="refs" class="references csl-bib-body" role="doc-bibliography" style="display: none">
<div id="ref-dengPCABasedLand2008" class="csl-entry" role="doc-biblioentry">
Deng, J. S. <em>et al.</em> (2008) <span>“<span>PCA</span>‐based land‐use change detection and analysis using multitemporal and multisensor satellite data,”</span> <em>International Journal of Remote Sensing</em>, 29(16), pp. 4823–4838. doi: <a href="https://doi.org/10.1080/01431160801950162">10.1080/01431160801950162</a>.
</div>
<div id="ref-ingebritsenPrincipalComponentsAnalysis1985" class="csl-entry" role="doc-biblioentry">
Ingebritsen, S. E. and Lyon, R. J. P. (1985) <span>“Principal components analysis of multitemporal image pairs,”</span> <em>International Journal of Remote Sensing</em>, 6(5), pp. 687–696. doi: <a href="https://doi.org/10.1080/01431168508948491">10.1080/01431168508948491</a>.
</div>
<div id="ref-licciardiLinearNonlinearPCA2012" class="csl-entry" role="doc-biblioentry">
Licciardi, G. <em>et al.</em> (2012) <span>“Linear <span>Versus Nonlinear PCA</span> for the <span>Classification</span> of <span>Hyperspectral Data Based</span> on the <span>Extended Morphological Profiles</span>,”</span> <em>IEEE Geoscience and Remote Sensing Letters</em>, 9(3), pp. 447–451. doi: <a href="https://doi.org/10.1109/LGRS.2011.2172185">10.1109/LGRS.2011.2172185</a>.
</div>
<div id="ref-rodarmelPrincipalComponentAnalysis2002" class="csl-entry" role="doc-biblioentry">
Rodarmel, C. and Shan, J. (2002) <span>“Principal <span>Component Analysis</span> for <span>Hyperspectral Image Classification</span>,”</span> <em>Surv Land inf Syst</em>, 62.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./week02.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">week02 - Sensor Satellite Presentation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./week04.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">week04 - Policy</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>